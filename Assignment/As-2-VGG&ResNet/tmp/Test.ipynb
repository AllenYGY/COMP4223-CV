{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T07:31:31.062788Z",
     "iopub.status.busy": "2023-11-01T07:31:31.062399Z",
     "iopub.status.idle": "2023-11-01T07:31:32.733337Z",
     "shell.execute_reply": "2023-11-01T07:31:32.732547Z",
     "shell.execute_reply.started": "2023-11-01T07:31:31.062755Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T07:31:32.734857Z",
     "iopub.status.busy": "2023-11-01T07:31:32.734615Z",
     "iopub.status.idle": "2023-11-01T07:31:38.867596Z",
     "shell.execute_reply": "2023-11-01T07:31:38.866790Z",
     "shell.execute_reply.started": "2023-11-01T07:31:32.734829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 784), (35000, 784), (7000,), (35000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('./train.csv')\n",
    "predict_df = pd.read_csv('./test.csv')\n",
    "\n",
    "# Divide the data into training and validation sets\n",
    "train_df, val_df = data_df.iloc[:7000].copy(), data_df.iloc[7000:].copy()\n",
    "\n",
    "# Extract the labels\n",
    "train_label = train_df.pop('label').values\n",
    "val_label = val_df.pop('label').values\n",
    "train_df.shape, val_df.shape, train_label.shape, val_label.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T07:31:38.869775Z",
     "iopub.status.busy": "2023-11-01T07:31:38.869530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 images out of 7000\n",
      "Processed 2000 images out of 7000\n",
      "Processed 3000 images out of 7000\n",
      "Processed 4000 images out of 7000\n",
      "Processed 5000 images out of 7000\n",
      "Processed 6000 images out of 7000\n",
      "Processed 1000 images out of 35000\n",
      "Processed 2000 images out of 35000\n",
      "Processed 3000 images out of 35000\n",
      "Processed 4000 images out of 35000\n",
      "Processed 5000 images out of 35000\n",
      "Processed 6000 images out of 35000\n",
      "Processed 7000 images out of 35000\n",
      "Processed 8000 images out of 35000\n",
      "Processed 9000 images out of 35000\n",
      "Processed 10000 images out of 35000\n",
      "Processed 11000 images out of 35000\n",
      "Processed 12000 images out of 35000\n",
      "Processed 13000 images out of 35000\n",
      "Processed 14000 images out of 35000\n",
      "Processed 15000 images out of 35000\n",
      "Processed 16000 images out of 35000\n",
      "Processed 17000 images out of 35000\n",
      "Processed 18000 images out of 35000\n",
      "Processed 19000 images out of 35000\n",
      "Processed 20000 images out of 35000\n",
      "Processed 21000 images out of 35000\n",
      "Processed 22000 images out of 35000\n",
      "Processed 23000 images out of 35000\n",
      "Processed 24000 images out of 35000\n",
      "Processed 25000 images out of 35000\n",
      "Processed 26000 images out of 35000\n",
      "Processed 27000 images out of 35000\n",
      "Processed 28000 images out of 35000\n",
      "Processed 29000 images out of 35000\n",
      "Processed 30000 images out of 35000\n",
      "Processed 31000 images out of 35000\n",
      "Processed 32000 images out of 35000\n",
      "Processed 33000 images out of 35000\n",
      "Processed 34000 images out of 35000\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def data_transform(df, target_size: int):\n",
    "    \"\"\"\n",
    "    Transform each image in the DataFrame to a specified size.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the image data, each row is a flattened image.\n",
    "    - target_size: int, the width and height to resize each image to.\n",
    "\n",
    "    Returns:\n",
    "    - array_list: list of transformed images as flattened arrays.\n",
    "    \"\"\"\n",
    "    transform = A.Compose([\n",
    "        A.Resize(width=target_size, height=target_size),\n",
    "    ])\n",
    "    array_list = []\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        # Reshape each row to 28x28, apply transform, and flatten to target_size*target_size\n",
    "        img = df.iloc[i, :].values.reshape(28, 28)\n",
    "        transformed = transform(image=img.astype(np.uint8))\n",
    "        transformed_image = transformed[\"image\"].astype(None)\n",
    "        data_img = transformed_image.reshape(target_size * target_size)\n",
    "        array_list.append(data_img)\n",
    "        \n",
    "        # Print progress every 1000 iterations\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(f\"Processed {i} images out of {df.shape[0]}\")    \n",
    "    # Perform garbage collection after processing\n",
    "    gc.collect()\n",
    "    return array_list\n",
    "\n",
    "\n",
    "train_array_list = data_transform(train_df, 224)\n",
    "val_array_list = data_transform(val_df,224 )\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the transformed data to disk\n",
    "with open('train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_array_list, f)\n",
    "\n",
    "with open('val_data.pkl', 'wb') as f:\n",
    "    pickle.dump(val_array_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 加载数据\n",
    "with open('val_data.pkl', 'rb') as f:\n",
    "    val_array_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttf= np.array(val_array_list)\n",
    "y_val = val_label[:ttf.shape[0]]\n",
    "x_val_tensor = torch.from_numpy(ttf/255).float()\n",
    "x_val_tensor = torch.reshape(x_val_tensor,(-1,1,224,224))\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "x_val_tensor.shape,y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "val_dataset = TensorDataset(x_val_tensor,y_val)\n",
    "val_dataload = DataLoader(val_dataset,batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(img_tensorData,model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensorData)\n",
    "    return prediction.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, init_weights=True):\n",
    "        super(VGGNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 2Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=2, in_channels=1, out_channels=64), # 1*224*224 -> 64*112*112\n",
    "            # Block 2: 2Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=2, in_channels=64, out_channels=128), # 64*112*112 -> 128*56*56\n",
    "            # Block 3: 3Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=3, in_channels=128, out_channels=256), # 128*56*56 -> 256*28*28\n",
    "            # Block 4: 3Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=3, in_channels=256, out_channels=512), # 256*28*28 -> 512*14*14\n",
    "            # Block 5: 3Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=3, in_channels=512, out_channels=512), # 512*14*14 -> 512*7*7\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096), # 512*7*7 -> 4096\n",
    "            # nn.ReLU(inplace=True), \n",
    "            # nn.Linear(4096, 4096),  # 4096 -> 4096\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(4096, num_classes),   # 4096 -> 10\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self._init_weights() # initialize weights\n",
    "\n",
    "    def vgg_block(self, num_convs, in_channels, out_channels):\n",
    "        layers = []\n",
    "        for _ in range(num_convs): # (1 conv + 1 relu) * num_convs\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels,\n",
    "                                    kernel_size=3, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))  # Batch Normalization\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 1 MaxPool\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # 5 VGG blocks\n",
    "        x = torch.flatten(x, start_dim=1) # flatten\n",
    "        x = self.classifier(x)  # 3 FC layers\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.constant_(layer.bias, 0)\n",
    "            elif isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.constant_(layer.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/t15z68h5545gnmg_nk6tn8r00000gn/T/ipykernel_68656/2530599672.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1 = torch.load('./VGG_net.pkl')\n"
     ]
    }
   ],
   "source": [
    "model1 = torch.load('./VGG_net.pkl')\n",
    "\n",
    "\n",
    "# # save result\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def save_result(y_pred):\n",
    "#     df = pd.DataFrame(y_pred, columns=['label'])\n",
    "#     df.index.name = 'id'\n",
    "#     df.to_csv('./result.csv')\n",
    "\n",
    "# y_pred = test(x_val_tensor, model1)\n",
    "# save_result(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, init_weights=True):\n",
    "        super(VGGNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: 2Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=2, in_channels=1, out_channels=64), # 1*224*224 -> 64*112*112\n",
    "            # Block 2: 2Conv + 1MaxPool\n",
    "            self.vgg_block(num_convs=2, in_channels=64, out_channels=128), # 64*112*112 -> 128*56*56\n",
    "            # Block 3: 3Conv + 1MaxPool\n",
    "            # self.vgg_block(num_convs=3, in_channels=128, out_channels=256), # 128*56*56 -> 256*28*28\n",
    "            # # Block 4: 3Conv + 1MaxPool\n",
    "            # self.vgg_block(num_convs=3, in_channels=256, out_channels=512), # 256*28*28 -> 512*14*14\n",
    "            # # Block 5: 3Conv + 1MaxPool\n",
    "            # self.vgg_block(num_convs=3, in_channels=512, out_channels=512), # 512*14*14 -> 512*7*7\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64*32*32, 256), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Linear(256, num_classes),  \n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self._init_weights() # initialize weights\n",
    "\n",
    "    def vgg_block(self, num_convs, in_channels, out_channels):\n",
    "        layers = []\n",
    "        for _ in range(num_convs): # (1 conv + 1 relu) * num_convs\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels,\n",
    "                                    kernel_size=3, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))  # Batch Normalization\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            in_channels = out_channels\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 1 MaxPool\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # 5 VGG blocks\n",
    "        x = torch.flatten(x, start_dim=1) # flatten\n",
    "        x = self.classifier(x)  # 3 FC layers\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.constant_(layer.bias, 0)\n",
    "            elif isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l_/t15z68h5545gnmg_nk6tn8r00000gn/T/ipykernel_21882/3506214248.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1 = torch.load('./net.pkl')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9651\n",
      "Precision: 0.9662\n",
      "Recall: 0.9651\n",
      "F1 Score: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9651428571428572,\n",
       " 0.9662066456472299,\n",
       " 0.9651428571428572,\n",
       " 0.9650539494495448)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def test(img_tensorData, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img_tensorData)\n",
    "    return prediction.cpu().numpy()\n",
    "\n",
    "def evaluate_model(test_dataloader, model):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1, y_pred, y_true\n",
    "\n",
    "test_dataset = TensorDataset(x_val_tensor, y_val)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "accuracy, precision, recall, f1, y_pred, y_true=evaluate_model(test_dataloader, model1)\n",
    "\n",
    "# save result\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# save prediction result and true label\n",
    "def save_result(y_pred, y_true):\n",
    "    df = pd.DataFrame(y_pred, columns=['label'])\n",
    "    df.index.name = 'id'\n",
    "    df.to_csv('./result.csv')\n",
    "\n",
    "    df = pd.DataFrame(y_true, columns=['label'])\n",
    "    df.index.name = 'id'\n",
    "    df.to_csv('./true_label.csv')\n",
    "\n",
    "\n",
    "# save evaluation result\n",
    "\n",
    "def save_evaluation_result(accuracy, precision, recall, f1):\n",
    "    df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1]\n",
    "    })\n",
    "    df.to_csv('./evaluation_result.csv', index=False)\n",
    "\n",
    "save_result(y_pred, y_true)\n",
    "save_evaluation_result(accuracy, precision, recall, f1)\n",
    "\n",
    "# Accuracy: 0.9651\n",
    "# Precision: 0.9662\n",
    "# Recall: 0.9651\n",
    "# F1 Score: 0.9651\n",
    "# (0.9651428571428572,\n",
    "#  0.9662066456472299,\n",
    "#  0.9651428571428572,\n",
    "#  0.9650539494495448)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
